{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import skopt\n",
    "from skopt.space import Real\n",
    "from skopt.learning import GaussianProcessRegressor as GPR\n",
    "from skopt.learning.gaussian_process.kernels import Matern, WhiteKernel, Product, ConstantKernel\n",
    "%run ./Functions.ipynb\n",
    "%run ./Val_Functions.ipynb\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex = True)\n",
    "mpl.rc('font', family = 'serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## second u0 is off-phase from the first by half a Lyapunov time\n",
    "u0 = np.array([7.432487609628195, 10.02071718705213, 29.62297428638419])\n",
    "\n",
    "dt        = 0.01\n",
    "t_lyap    = 0.9**(-1)\n",
    "N_lyap    = int(t_lyap/dt)  # number of time steps in one Lyapunov time\n",
    "\n",
    "# number of time steps for washout, train, validation and PH window\n",
    "N_washout = 1*N_lyap\n",
    "N_train   = 8*N_lyap\n",
    "N_val     = 3*N_lyap\n",
    "N_tstart  = 24*N_lyap #start for the test set\n",
    "N_test    = 500*N_lyap\n",
    "\n",
    "norm      = np.array([35.23020746, 45.09776766, 36.07598481])\n",
    "\n",
    "# generate data \n",
    "U         = solve_ode(N_washout+N_train+N_val+N_test, dt, u0)\n",
    "\n",
    "# washout\n",
    "U_washout = U[:N_washout]\n",
    "# training\n",
    "U_t       = U[N_washout:N_washout+N_train-1]\n",
    "Y_t       = U[N_washout+1:N_washout+N_train]\n",
    "# training + validation\n",
    "U_tv      = U[N_washout:N_washout+N_train+N_val-1]\n",
    "Y_tv      = U[N_washout+1:N_washout+N_train+N_val]\n",
    "# validation\n",
    "Y_val     = U[N_washout+N_train:N_washout+N_train+N_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Results From  Optimization Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_informed = True\n",
    "if model_informed:\n",
    "    string = '_MI.h5'\n",
    "    %run ./Functions_MI.ipynb\n",
    "else:\n",
    "    string = '.h5'\n",
    "\n",
    "#BO and Grid Search in SSV\n",
    "hf       = h5py.File('./data/Lor_short_SSV_50_5' + str(string),'r')\n",
    "Min_25G  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_SSV_50_7' + str(string),'r')\n",
    "Min_50G  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "# #BO and Grid Search in RVC \n",
    "hf       = h5py.File('./data/Lor_short_RVC_50_5' + str(string),'r')\n",
    "Min_25G_mmv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_RVC_50_7' + str(string),'r')\n",
    "Min_50G_mmv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "# BO and Grid Search in WFV\n",
    "hf       = h5py.File('./data/Lor_short_WFV_50_5' + str(string),'r')\n",
    "Min_25G_wfv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_WFV_50_7' + str(string),'r')\n",
    "Min_50G_wfv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "#BO and Grid Search in KFV \n",
    "hf       = h5py.File('./data/Lor_short_KFV_50_5' + str(string),'r')\n",
    "Min_25G_kfv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_KFV_50_7' + str(string),'r')\n",
    "Min_50G_kfv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "#BO and Grid Search in RV \n",
    "hf       = h5py.File('./data/Lor_short_RV_50_5' + str(string),'r')\n",
    "Min_25G_mv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_RV_50_7' + str(string),'r')\n",
    "Min_50G_mv  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "#BO and Grid Search in KFC\n",
    "hf       = h5py.File('./data/Lor_short_KFC_50_5' + str(string),'r')\n",
    "Min_25G_kfo  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_KFC_50_7' + str(string),'r')\n",
    "Min_50G_kfo  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "#BO and Grid Search WFC\n",
    "hf       = h5py.File('./data/Lor_short_WFC_50_5' + str(string),'r')\n",
    "Min_25G_wfc  = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "hf       = h5py.File('./data/Lor_short_WFC_50_7' + str(string),'r')\n",
    "Min_50G_wfc  = np.array(hf.get('minimum'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESN Initiliazation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_in = 1.0 #input bias\n",
    "bias_out = 1.0 #output bias \n",
    "N_units = 100 #units in the reservoir\n",
    "dim = 3 # dimension of inputs (and outputs) \n",
    "connectivity   = 3 \n",
    "\n",
    "sigma_in = 1.0 #input scaling\n",
    "rho = 1.0  # spectral radius\n",
    "sparseness =  1 - connectivity/(N_units-1) \n",
    "\n",
    "tikh = 1e-11  # Tikhonov factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions in the test set\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Computes MSE and PH in the test set of N_test points\"\"\"\n",
    "    \n",
    "    global rho, sigma_in\n",
    "    rho      = x[0]\n",
    "    sigma_in = x[1] \n",
    "                \n",
    "    #Train on the entire dataset\n",
    "    Wout     = train(U_washout, U_tv, Y_tv, tikh)[1]\n",
    "\n",
    "    N_test   = 100 # N_test intervals\n",
    "    Mean_MSE = 0\n",
    "    Mean_PH  = 0\n",
    "    kk       = 5   # the PH is computed up to kk*N_val for each interval\n",
    "    \n",
    "    #Different Folds in the cross-validation\n",
    "    for i in range(N_test):\n",
    "        \n",
    "        # data for washout and target in each interval\n",
    "        U_wash    = U[N_tstart - N_washout +i*N_val : N_tstart+i*N_val]\n",
    "        Y_t_MSE   = U[N_tstart+i*N_val:N_tstart+i*N_val+N_val] \n",
    "        Y_t_PH    = U[N_tstart+i*N_val:N_tstart+i*N_val+kk*N_val] \n",
    "        \n",
    "        #washout for each interval\n",
    "        xa1       = open_loop(U_wash, np.zeros(N_units))[-1]\n",
    "        \n",
    "        # Mean Square Error\n",
    "        Yh_t_MSE  = closed_loop(N_val-1, xa1, Wout)[0]\n",
    "        Mean1     = np.log10(np.mean(((Yh_t_MSE-Y_t_MSE))**2))\n",
    "        # np.isnan because trajectory may become unbounded in model-informed architecture\n",
    "        if np.isnan(Mean1):\n",
    "            Mean1 = 10\n",
    "        Mean_MSE += Mean1\n",
    "        \n",
    "        # Prediction Horizon\n",
    "        Mean_PH  += predictability_horizon(xa1,Y_t_PH,Wout)\n",
    "                \n",
    "    return Mean_MSE/N_test, Mean_PH/N_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Ensemble in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble    : 1\n",
      "Ensemble    : 2\n",
      "Ensemble    : 3\n",
      "Ensemble    : 4\n",
      "Ensemble    : 5\n",
      "Ensemble    : 6\n",
      "Ensemble    : 7\n",
      "Ensemble    : 8\n",
      "Ensemble    : 9\n",
      "Ensemble    : 10\n",
      "Ensemble    : 11\n",
      "Ensemble    : 12\n",
      "Ensemble    : 13\n",
      "Ensemble    : 14\n",
      "Ensemble    : 15\n",
      "Ensemble    : 16\n",
      "Ensemble    : 17\n",
      "Ensemble    : 18\n",
      "Ensemble    : 19\n",
      "Ensemble    : 20\n",
      "Ensemble    : 21\n",
      "Ensemble    : 22\n",
      "Ensemble    : 23\n",
      "Ensemble    : 24\n",
      "Ensemble    : 25\n",
      "Ensemble    : 26\n",
      "Ensemble    : 27\n",
      "Ensemble    : 28\n",
      "Ensemble    : 29\n",
      "Ensemble    : 30\n",
      "Ensemble    : 31\n",
      "Ensemble    : 32\n",
      "Ensemble    : 33\n",
      "Ensemble    : 34\n",
      "Ensemble    : 35\n",
      "Ensemble    : 36\n",
      "Ensemble    : 37\n",
      "Ensemble    : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ar994/.local/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in double_scalars\n",
      "/home/ar994/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble    : 39\n",
      "Ensemble    : 40\n",
      "Ensemble    : 41\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Compute Ensemble\n",
    "ensemble = 50\n",
    "\n",
    "# Initialize the arrays \n",
    "res_Gr     = np.zeros((ensemble,2))\n",
    "res_BO     = np.zeros((ensemble,2))\n",
    "res_Gr_mmv = np.zeros((ensemble,2))\n",
    "res_BO_mmv = np.zeros((ensemble,2))\n",
    "res_Gr_wfv = np.zeros((ensemble,2))\n",
    "res_BO_wfv = np.zeros((ensemble,2))\n",
    "res_Gr_kfv = np.zeros((ensemble,2))\n",
    "res_BO_kfv = np.zeros((ensemble,2))\n",
    "res_Gr_mv   = np.zeros((ensemble,2))\n",
    "res_BO_mv   = np.zeros((ensemble,2))\n",
    "res_Gr_kfo  = np.zeros((ensemble,2))\n",
    "res_BO_kfo  = np.zeros((ensemble,2))\n",
    "res_Gr_wfc  = np.zeros((ensemble,2))\n",
    "res_BO_wfc  = np.zeros((ensemble,2))\n",
    "\n",
    "for i in range(ensemble):\n",
    "     \n",
    "    print('Ensemble    :',i+1)\n",
    "        \n",
    "    # Win and W generation\n",
    "    seed= i+1\n",
    "    rnd = np.random.RandomState(seed)\n",
    "\n",
    "    Win = np.zeros((dim+1, N_units))\n",
    "    for j in range(N_units):\n",
    "        Win[rnd.randint(0, dim+1),j] = rnd.uniform(-1, 1) #only one element different from zero per row\n",
    "    \n",
    "    # practical way to set the sparseness\n",
    "    W = rnd.uniform(-1, 1, (N_units, N_units)) * (rnd.rand(N_units, N_units) < (1-sparseness))\n",
    "    spectral_radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "    W /= spectral_radius #scaled to have unitary spec radius\n",
    "    \n",
    "    #Compute the performance in the test set for the best hyperparameters\n",
    "    temp = f(Min_50G[i,:2])\n",
    "    res_Gr[i,0]  = temp[0]\n",
    "    res_Gr[i,1]  = temp[1]\n",
    "        \n",
    "    temp = f(Min_25G[i,:2])\n",
    "    res_BO[i,0]  = temp[0]\n",
    "    res_BO[i,1]  = temp[1]\n",
    "        \n",
    "    temp = f(Min_50G_mmv[i,:2])\n",
    "    res_Gr_mmv[i,0]  = temp[0]\n",
    "    res_Gr_mmv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_mmv[i,:2])\n",
    "    res_BO_mmv[i,0]  = temp[0]\n",
    "    res_BO_mmv[i,1]  = temp[1]\n",
    "        \n",
    "    temp = f(Min_50G_wfv[i,:2])\n",
    "    res_Gr_wfv[i,0]  = temp[0]\n",
    "    res_Gr_wfv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_wfv[i,:2])\n",
    "    res_BO_wfv[i,0]  = temp[0]\n",
    "    res_BO_wfv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_50G_kfv[i,:2])\n",
    "    res_Gr_kfv[i,0]  = temp[0]\n",
    "    res_Gr_kfv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_kfv[i,:2])\n",
    "    res_BO_kfv[i,0]  = temp[0]\n",
    "    res_BO_kfv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_50G_kfo[i,:2])\n",
    "    res_Gr_kfo[i,0]  = temp[0]\n",
    "    res_Gr_kfo[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_kfo[i,:2])\n",
    "    res_BO_kfo[i,0]  = temp[0]\n",
    "    res_BO_kfo[i,1]  = temp[1]\n",
    "            \n",
    "    temp = f(Min_50G_mv[i,:2])\n",
    "    res_Gr_mv[i,0]  = temp[0]\n",
    "    res_Gr_mv[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_mv[i,:2])\n",
    "    res_BO_mv[i,0]  = temp[0]\n",
    "    res_BO_mv[i,1]  = temp[1]\n",
    "\n",
    "    temp = f(Min_50G_wfc[i,:2])\n",
    "    res_Gr_wfc[i,0]  = temp[0]\n",
    "    res_Gr_wfc[i,1]  = temp[1]\n",
    "    \n",
    "    temp = f(Min_25G_wfc[i,:2])\n",
    "    res_BO_wfc[i,0]  = temp[0]\n",
    "    res_BO_wfc[i,1]  = temp[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Results\n",
    "\n",
    "fln = './data/Short_Lorenz_PostProc' + str(string)\n",
    "\n",
    "hf = h5py.File(fln,'w')\n",
    "hf.create_dataset('res_Gr     ',data=res_Gr)\n",
    "hf.create_dataset('res_BO     ',data=res_BO)\n",
    "hf.create_dataset('res_Gr_mmv ',data=res_Gr_mmv)\n",
    "hf.create_dataset('res_BO_mmv ',data=res_BO_mmv)\n",
    "hf.create_dataset('res_Gr_mv  ',data=res_Gr_mv)\n",
    "hf.create_dataset('res_BO_mv  ',data=res_BO_mv)\n",
    "hf.create_dataset('res_Gr_kfv ',data=res_Gr_kfv)\n",
    "hf.create_dataset('res_BO_kfv ',data=res_BO_kfv)\n",
    "hf.create_dataset('res_Gr_kfo ',data=res_Gr_kfo)\n",
    "hf.create_dataset('res_BO_kfo ',data=res_BO_kfo)\n",
    "hf.create_dataset('res_Gr_wfv ',data=res_Gr_wfv)\n",
    "hf.create_dataset('res_BO_wfv ',data=res_BO_wfv)\n",
    "hf.create_dataset('res_Gr_wfc ',data=res_Gr_wfc)\n",
    "hf.create_dataset('res_BO_wfc ',data=res_BO_wfc)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Ensmeble in the test set with fixed hyperparameters\n",
    "We compute the performance of the ensemble using the same hyperparameters for all the networks.\n",
    "\n",
    "The hyperparameters used are the ones obtained through Bayesian Optimization in the first network using chaotic Recycle Validation and chaotic K-Fold Validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble    : 1\n",
      "Ensemble    : 2\n",
      "Ensemble    : 3\n",
      "Ensemble    : 4\n",
      "Ensemble    : 5\n",
      "Ensemble    : 6\n",
      "Ensemble    : 7\n",
      "Ensemble    : 8\n",
      "Ensemble    : 9\n",
      "Ensemble    : 10\n",
      "Ensemble    : 11\n",
      "Ensemble    : 12\n",
      "Ensemble    : 13\n",
      "Ensemble    : 14\n",
      "Ensemble    : 15\n",
      "Ensemble    : 16\n",
      "Ensemble    : 17\n",
      "Ensemble    : 18\n",
      "Ensemble    : 19\n",
      "Ensemble    : 20\n",
      "Ensemble    : 21\n",
      "Ensemble    : 22\n",
      "Ensemble    : 23\n",
      "Ensemble    : 24\n",
      "Ensemble    : 25\n",
      "Ensemble    : 26\n",
      "Ensemble    : 27\n",
      "Ensemble    : 28\n",
      "Ensemble    : 29\n",
      "Ensemble    : 30\n",
      "Ensemble    : 31\n",
      "Ensemble    : 32\n",
      "Ensemble    : 33\n",
      "Ensemble    : 34\n",
      "Ensemble    : 35\n",
      "Ensemble    : 36\n",
      "Ensemble    : 37\n",
      "Ensemble    : 38\n",
      "Ensemble    : 39\n",
      "Ensemble    : 40\n",
      "Ensemble    : 41\n",
      "Ensemble    : 42\n",
      "Ensemble    : 43\n",
      "Ensemble    : 44\n",
      "Ensemble    : 45\n",
      "Ensemble    : 46\n",
      "Ensemble    : 47\n",
      "Ensemble    : 48\n",
      "Ensemble    : 49\n",
      "Ensemble    : 50\n",
      "CPU times: user 4min 15s, sys: 14.5 ms, total: 4min 16s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "model_informed = False\n",
    "if model_informed:\n",
    "    %run ./Functions_MI.ipynb\n",
    "\n",
    "#Compute Ensemble\n",
    "ensemble = 50\n",
    "\n",
    "# Initialize the arrays \n",
    "res_BO_mmv_fix = np.zeros((ensemble,2))\n",
    "res_BO_kfo_fix = np.zeros((ensemble,2))\n",
    "\n",
    "for i in range(ensemble):\n",
    "     \n",
    "    print('Ensemble    :',i+1)\n",
    "        \n",
    "    # Win and W generation\n",
    "    seed= i+1\n",
    "    rnd = np.random.RandomState(seed)\n",
    "\n",
    "    Win = np.zeros((dim+1, N_units))\n",
    "    for j in range(N_units):\n",
    "        Win[rnd.randint(0, dim+1),j] = rnd.uniform(-1, 1) #only one element different from zero per row\n",
    "    \n",
    "    # practical way to set the sparseness\n",
    "    W = rnd.uniform(-1, 1, (N_units, N_units)) * (rnd.rand(N_units, N_units) < (1-sparseness))\n",
    "    spectral_radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "    W /= spectral_radius #scaled to have unitary spec radius\n",
    "    \n",
    "    #Compute the performance in the test set for the best hyperparameters\n",
    "    temp = f(Min_25G_mmv[0,:2])\n",
    "    res_BO_mmv_fix[i,0]  = temp[0]\n",
    "    res_BO_mmv_fix[i,1]  = temp[1]\n",
    "        \n",
    "    temp = f(Min_25G_kfo[0,:2])\n",
    "    res_BO_kfo_fix[i,0]  = temp[0]\n",
    "    res_BO_kfo_fix[i,1]  = temp[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Results\n",
    "\n",
    "fln = './data/Short_Lorenz_PostProc_fix.h5'\n",
    "\n",
    "hf = h5py.File(fln,'w')\n",
    "hf.create_dataset('res_BO_mmv_fix',data=res_BO_mmv_fix)\n",
    "hf.create_dataset('res_BO_kfo_fix',data=res_BO_kfo_fix)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison SSV in validation and 12 to 15 LTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.76 s, sys: 0 ns, total: 3.76 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# We use only one interval for the test set (12 to 15LTs) to compute the MSE\n",
    "# Test1 is implemented in Functions.ipynb\n",
    "\n",
    "#Compute Ensemble\n",
    "ensemble = 50\n",
    "\n",
    "#Computing \n",
    "res_Gr1     = np.zeros((ensemble,1))\n",
    "res_BO1     = np.zeros((ensemble,1))\n",
    "\n",
    "for i in range(ensemble):\n",
    "        \n",
    "    # Win and W generation\n",
    "    seed =i+1\n",
    "    rnd = np.random.RandomState(seed)\n",
    "\n",
    "    Win = np.zeros((dim+1, N_units))\n",
    "    for j in range(N_units):\n",
    "        Win[rnd.randint(0, dim+1),j] = rnd.uniform(-1, 1)\n",
    "        \n",
    "    W = rnd.uniform(-1, 1, (N_units, N_units)) * (rnd.rand(N_units, N_units) < (1-sparseness))\n",
    "    spectral_radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "    W /= spectral_radius\n",
    "    \n",
    "    # \n",
    "    temp = Test1(Min_50G[i,:2])\n",
    "    res_Gr1[i,0]  = 10**temp\n",
    "    \n",
    "    temp = Test1(Min_25G[i,:2])\n",
    "    res_BO1[i,0]  = 10**temp\n",
    "    \n",
    "fln = './data/Short_Lorenz_PostProc2.h5'\n",
    "\n",
    "hf = h5py.File(fln,'w')\n",
    "hf.create_dataset('res_Gr1     ',data=res_Gr1)\n",
    "hf.create_dataset('res_BO1     ',data=res_BO1)\n",
    "hf.create_dataset('Min_25G     ',data=10**Min_25G)\n",
    "hf.create_dataset('Min_50G     ',data=10**Min_50G)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model-informed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
