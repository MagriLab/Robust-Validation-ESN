{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODE Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_euler(ddt, u0, T, *args):\n",
    "    u = np.empty((T.size, u0.size))\n",
    "    u[0] = u0\n",
    "    for i in range(1, T.size):\n",
    "        u[i] = u[i-1] + (T[i] - T[i-1]) * ddt(u[i-1], T[i-1], *args)\n",
    "    return u\n",
    "\n",
    "def ddt(u, t, params):\n",
    "    beta, rho, sigma = params\n",
    "    x, y, z = u\n",
    "    return np.array([sigma*(y-x), x*(rho-z)-y, x*y-beta*z])\n",
    "\n",
    "def solve_ode(N, dt, u0, params=[8/3, 28, 10]):\n",
    "    \"\"\"\n",
    "        Solves the ODEs for N time steps starting from u0.\n",
    "        Returned values are normalized.\n",
    "\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            u0: initial condition\n",
    "            norm: normalisation factor of u0 (None if not normalised)\n",
    "            params: parameters for ODE\n",
    "        Returns:\n",
    "            normalized time series of shape (N+1, u0.size)\n",
    "    \"\"\"\n",
    "\n",
    "    T = np.arange(N+1) * dt\n",
    "    U = forward_euler(ddt, u0, T, params)\n",
    "\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the POD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Proper Orthogonal Decomposition to compute the reduced order model\n",
    "\n",
    "# portion of U to be used for the POD (same length of entire dataset)\n",
    "N_POD = N_washout+N_train+N_val\n",
    "T     = np.arange(N_POD)*dt/t_lyap\n",
    "qPod = U[:N_POD].copy()\n",
    "\n",
    "# subtract the mean from the original signal\n",
    "b    = np.mean(qPod,axis=0)\n",
    "for i in range(3):\n",
    "    qPod[:,i] = qPod[:,i] - b[i]\n",
    "\n",
    "# covariance matrix\n",
    "C    = 1/(N_POD-1) * np.dot(qPod.transpose(),qPod)\n",
    "\n",
    "# eigenvalues and eigenvectors of C are the energies and modes of the POD\n",
    "lam, phi = np.linalg.eig(C)\n",
    "# print('energies=', lam)\n",
    "\n",
    "# selecting only the first NPOD modes\n",
    "NPOD  = 2\n",
    "pos   = np.argsort(lam)\n",
    "V     = phi[:,pos][:,-NPOD:] \n",
    "\n",
    "# computing the maximum variation of the reduced order model variables to normalize them when \n",
    "# concatenated to the reservoir state (so that they are comparable to the other values in the vector)\n",
    "proj   = np.dot(V.transpose(),qPod.transpose()).transpose() #projection on the reduced spacespace\n",
    "m      = proj.min(axis=0)\n",
    "M      = proj.max(axis=0)\n",
    "norm_P = M-m\n",
    "\n",
    "# Computing matrices descrbing the evolution in the reduced order space\n",
    "sigma, beta, rho = 10.0, 8.0/3, 28.0\n",
    "# linear part of the equations\n",
    "L = np.array([[      -sigma, sigma,     0.],\n",
    "              [ rho,            -1,     0.],\n",
    "              [          0.,            0., -beta]])\n",
    "# projection of onto the POD-subspace the linear part\n",
    "A1 = np.dot(V.transpose(),np.dot(L,V))\n",
    "A2 = np.dot(V.transpose(),np.dot(L,b))\n",
    "\n",
    "def dddt(q):\n",
    "    x, y, z = np.dot(V,q) + b \n",
    "    # last term below is the nonlinear part projected onto the POD-subspace\n",
    "    return np.dot(A1,q) + A2 + np.dot(V.transpose(), np.array([0., -x*z, x*y]))\n",
    "\n",
    "# Compute the prediction of the POD-model using FE, then normalize prediction\n",
    "def Gal_POD(q):\n",
    "    q_red0 = np.dot(V.transpose(), q-b)\n",
    "    q_red1 = q_red0 + dt * dddt(q_red0)\n",
    "    return q_red1/norm_P "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Informed ESN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESN with bias architecture\n",
    "\n",
    "def step(x_pre, u):\n",
    "    \"\"\" Advances one ESN time step.\n",
    "        Args:\n",
    "            x_pre: reservoir state\n",
    "            u: input\n",
    "        Returns:\n",
    "            new augmented state (new state with bias_out appended)\n",
    "    \"\"\"\n",
    "    # reduced\n",
    "    u_POD      = Gal_POD(u)\n",
    "    # input is normalized and input bias added\n",
    "    u_augmented = np.hstack([u/norm, bias_in]) \n",
    "    # hyperparameters are explicit here\n",
    "    x_post = np.tanh(np.dot(u_augmented*sigma_in, Win) + rho*np.dot(x_pre, W)) \n",
    "    # output bias added\n",
    "    x_augmented = np.hstack([x_post, bias_out, u_POD])\n",
    "\n",
    "    return x_augmented\n",
    "\n",
    "def open_loop(U, x0):\n",
    "    \"\"\" Advances ESN in open-loop.\n",
    "        Args:\n",
    "            U: input time series\n",
    "            x0: initial reservoir state\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "    \"\"\"\n",
    "    u_POD       = Gal_POD(U[0])\n",
    "    N = U.shape[0]\n",
    "    Xa = np.empty((N+1, N_units+NPOD+1))\n",
    "    Xa[0] = np.hstack([x0, bias_out, u_POD])\n",
    "    for i in 1+np.arange(N):\n",
    "        Xa[i] = step(Xa[i-1,:N_units], U[i-1])\n",
    "\n",
    "    return Xa\n",
    "\n",
    "def closed_loop(N, x0, Wout):\n",
    "    \"\"\" Advances ESN in closed-loop.\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            x0: initial reservoir state\n",
    "            Wout: output matrix\n",
    "        Returns:\n",
    "            time series of prediction\n",
    "            final augmented reservoir state\n",
    "    \"\"\"\n",
    "    xa = x0.copy()\n",
    "    Yh = np.empty((N+1, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "    for i in 1+np.arange(N):\n",
    "        xa = step(xa[:N_units], Yh[i-1])\n",
    "        Yh[i] = np.dot(xa, Wout)\n",
    "\n",
    "    return Yh, xa\n",
    "\n",
    "def train(U_washout, U_train, Y_train, tikh):\n",
    "    \"\"\" Trains ESN.\n",
    "        Args:\n",
    "            U_washout: washout input time series\n",
    "            U_train: training input time series\n",
    "            tikh: Tikhonov factor\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "            optimal output matrix\n",
    "    \"\"\"\n",
    "    ## washout phase\n",
    "    xf_washout = open_loop(U_washout, np.zeros(N_units))[-1,:N_units]\n",
    "\n",
    "    ## open-loop train phase\n",
    "    Xa = open_loop(U_train, xf_washout)\n",
    "    \n",
    "    ## Ridge Regression\n",
    "    LHS  = np.dot(Xa[1:].T, Xa[1:]) + tikh*np.eye(N_units+1+NPOD)\n",
    "    RHS  = np.dot(Xa[1:].T, Y_train)\n",
    "    Wout = np.linalg.solve(LHS, RHS)\n",
    "\n",
    "    return Xa, Wout, LHS, RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_horizon(xa, Y, Wout):\n",
    "    \"\"\" Compute predictability horizon. It evolves the network until the\n",
    "        error is greater than the threshold. Before that it initialises\n",
    "        the network by running a washout phase.\n",
    "        \n",
    "        Args:\n",
    "            threshold: error threshold\n",
    "            U_washout: time series for washout\n",
    "            Y: time series to compare prediction\n",
    "        \n",
    "        Returns:\n",
    "            predictability horizon (in time units, not Lyapunov times)\n",
    "            time series of normalised error\n",
    "            time series of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate denominator of the normalised error\n",
    "    error_denominator = np.mean(np.sum((Y)**2, axis=1))\n",
    "\n",
    "    N     = Y.shape[0]\n",
    "    E     = np.zeros(N)\n",
    "    Yh    = np.zeros((N, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "\n",
    "    for i in range(1, N):\n",
    "        # advance one step\n",
    "        xa = step(xa[:N_units], Yh[i-1])\n",
    "        Yh[i] = np.dot(xa, Wout)\n",
    "\n",
    "        # calculate error\n",
    "        error_numerator = np.sum(((Yh[i]-Y[i]))**2)\n",
    "        E[i] = np.sqrt(error_numerator/error_denominator)\n",
    "\n",
    "        if E[i] > threshold:\n",
    "            break\n",
    "            \n",
    "    return i/N_lyap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
